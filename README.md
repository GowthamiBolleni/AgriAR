AgriAR: Smart Farming AssistantAgriAR is an AI-powered smart farming assistant designed to help farmers with soil analysis, disease detection, and crop recommendations for sustainable agriculture. It features a web-based interface for easy interaction and a FastAPI backend for handling analysis requests and data management.FeaturesSoil Analysis: Upload soil images to get insights into soil type, fertility, pH level, and organic matter.Crop Recommendations: Receive crop suggestions based on soil analysis and mock weather conditions.Disease Detection: Upload images of affected plant leaves to detect diseases and get treatment recommendations (organic and chemical).Analytics Dashboard: View statistics on soil analyses, disease detections, and recent user activities.Community Features: Includes mock integrations for WhatsApp support and multi-language voice assistance.Camera Integration: Directly capture images using your device's camera for analysis.Technologies UsedBackend (Python)FastAPI: A modern, fast (high-performance) web framework for building APIs.Uvicorn: An ASGI server for running FastAPI applications.Python-Multipart: For handling form data, especially file uploads.OpenCV (cv2): Used for basic image processing in mock ML models.NumPy: For numerical operations, especially with image arrays.Pillow (PIL): For image manipulation.TensorFlow: Included as a dependency for potential future integration of actual ML models (currently using mock models).SQLite3: Lightweight database for storing crop, disease, and user activity data.Frontend (HTML, CSS, JavaScript)HTML5: Structure of the web application.Tailwind CSS: A utility-first CSS framework for rapid UI development and responsive design. (Loaded via CDN)JavaScript (Vanilla JS): Handles all frontend logic, DOM manipulation, API calls to the backend, and interactive elements.Font Awesome: For icons used throughout the application. (Loaded via CDN)Project StructureAgriAR_Project/
├── app.py                  # FastAPI Backend application
├── frontend.html           # HTML Frontend (main web page)
└── agri_data.db            # SQLite database (created on first run of app.py)
How to Run the ProjectFollow these steps to set up and run both the backend and frontend of the AgriAR application.1. Backend Setup (app.py)Save the Backend File:Save the provided Python code for the backend as app.py in your project directory (e.g., AgriAR_Project/app.py).Open Terminal/Command Prompt:Navigate to your project's root directory (AgriAR_Project/) in your terminal or VS Code's integrated terminal.cd path/to/AgriAR_Project
Create and Activate a Python Virtual Environment (Recommended):This isolates your project's dependencies.python -m venv venv
Activate the virtual environment:On Windows (PowerShell):.\venv\Scripts\activate
On Windows (Command Prompt):venv\Scripts\activate.bat
On macOS/Linux:source venv/bin/activate
You should see (venv) at the beginning of your terminal prompt once activated.Install Required Python Packages:With the virtual environment activated, install all necessary libraries:pip install fastapi uvicorn python-multipart opencv-python numpy Pillow tensorflow requests
Run the FastAPI Backend Server:Keep the virtual environment activated and run:uvicorn app:app --reload --host 0.0.0.0 --port 8000
The terminal will show messages indicating that the server is running, typically on http://127.0.0.1:8000. Keep this terminal window open as the backend needs to be running for the frontend to function.2. Frontend Setup (frontend.html)Save the Frontend File:Save the provided HTML code for the frontend as frontend.html (or index.html) in the same AgriAR_Project/ directory.Open in Web Browser:Locate the frontend.html file in your file explorer.Double-click frontend.html to open it in your preferred web browser (e.g., Chrome, Firefox, Edge).UsageOnce both the backend server and the frontend HTML page are running:Navigate the Tabs: Click on "Soil Analysis," "Disease Detection," "Analytics," and "Community" tabs to explore different features.Image Analysis:On "Soil Analysis" or "Disease Detection" tabs, click "Upload Image" to select a photo from your computer.Alternatively, click "Use Camera" to activate your webcam and "Capture Photo" to take a picture for analysis.The results will be displayed below the upload/camera options (using mock data from the backend).Voice Assistant: On the "Community" tab, click "Start Voice Query" to simulate a voice interaction. A mock alert will provide a response.Analytics: The "Analytics" tab displays mock statistics and recent activities, demonstrating how data would be aggregated.Note: The machine learning models (SoilAnalyzer, DiseaseDetector) and external integrations (Weather API, WhatsApp) in app.py are currently mock implementations. They provide dummy data to demonstrate the application's flow without requiring actual complex ML setups or external API keys.Future EnhancementsIntegrate actual TensorFlow/Keras models for real soil and disease analysis.Implement real-time weather API integration.Develop full WhatsApp Business API integration.Add actual speech-to-text and text-to-speech for the voice assistant.Expand the database with more comprehensive crop and disease data.Implement user authentication and personalized dashboards.Add interactive maps for disease outbreaks.
